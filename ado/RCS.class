*Class to run Rapid Consumption Survey simulations
version 14.2

class RCS {
	string dirbase
	string lc_sdTemp
	string lc_sdOut
	*use status to ensure class is executed in right sequence:
	* 1 prepared
	* 2 masked
	* 3 estimated
	* 4 collated
	* 5 analyzed
	double status = 0
	double nmodules
	double nsim
	double nmi
	string lmethod
	double rseed = 23081980
	RCS_estimator estimator = .RCS_estimator.new
}
program .new
	*check whether package is installed
	capture : which vselect
	if (_rc) {
		display as result in smcl `"Please install package {it:vselect} from SSC in order to run this do-file;"' _newline `"you can do so by clicking this link: {stata "ssc install vselect":auto-install vselect}"'
		exit 199
	}
	capture : which esttab
	if (_rc) {
		display as result in smcl `"Please install package {it:st0085_2} for esttab from SSC in order to run this do-file;"' _newline `"you can do so by clicking this link: {stata "net install st0085_2.pkg":net install st0085_2.pkg, from(http://www.stata-journal.com/software/sj14-2/)}"'
		exit 199
	}
	capture : which dirlist
	if (_rc) {
		display as result in smcl `"Please install package {it:dirlist} from SSC in order to run this do-file;"' _newline `"you can do so by clicking this link: {stata "ssc install dirlist":auto-install dirlist}"'
		exit 199
	}
	capture : which fastgini
	if (_rc) {
		display as result in smcl `"Please install package {it:fastgini} from SSC in order to run this do-file;"' _newline `"you can do so by clicking this link: {stata "ssc install fastgini":auto-install fastgini}"'
		exit 199
	}
end
program define .fse, rclass
	args vref vest
	tempvar d r_d
	gen `d' = (`vest' - `vref')
	gen `r_d' = `d' / `vref'
	quiet: summ `d'
	local xb = r(mean)
	quiet: summ `r_d'
	local r_xb = r(mean)
	tempvar sd r_sd
	gen `sd' = (`d')^2
	gen `r_sd' = (`r_d')^2
	quiet: summ `sd'
	local xsd = sqrt(r(mean))
	quiet: summ `r_sd'
	local r_xsd = sqrt(r(mean))
	drop `d' `r_d' `sd' `r_sd'
	return scalar bias = `xb'
	*note that se is the same as the rmse
	return scalar se = `xsd'
	return scalar rmse = `xsd'
	return scalar rbias = `r_xb'
	return scalar rse = `r_xsd'
	*coefficient of variation
	quiet: summ `vref'
	return scalar cv = `xsd' / r(mean)
end
program .prepare
	syntax using/, dirbase(string) nsim(integer) nmodules(integer) ncoref(integer) ncorenf(integer) [force erase train(integer 0) shares(string) rseed(integer -1)]
	*prepare output directories
	.dirbase = "`dirbase'"
	if ("`erase'"!="") shell rmdir "`.dirbase'" /s /q
	capture: mkdir "`.dirbase'"
	.lc_sdTemp = "`dirbase'/Temp"
	capture: mkdir "`.lc_sdTemp'"
	capture: confirm file "`.lc_sdTemp'/nul"
	scalar r = _rc
	.lc_sdOut = "`dirbase'/Out"
	capture: mkdir "`.lc_sdOut'"
	capture: confirm file "`.lc_sdOut'/nul"
	if (_rc + r>0) {
		di as error "RCS.prepare: could not create Temp or Out directories in `.dirbase'."
		error _rc
	}
	*save parameters
	.nmodules = `nmodules'
	.nsim = `nsim'
	if `rseed'>0 .rseed = `rseed'
	set seed `.rseed'
	*check if we need to call
	capture confirm file "`.lc_sdTemp'/HHData.dta"
	quiet: if ((_rc>0) | ("`force'"!="")) {
		use "`using'", clear
		*check whether variables exist and are non-missing
		local lv = "hhid strata urban cluster weight hhsize xdurables"
		foreach v of local lv {
			capture: assert !missing(`v')
			if _rc == 9 {
				di as error "RCS.prepare: ensure that variable `v' has no missing values."
				error _rc
			}
			else if _rc ==111 {
				di as error "RCS.prepare: ensure that variable `v' exists."
				error _rc
			}
		}
		local lsv = "mcon_* mcat_* xfood* xnonfood*"
		foreach sv of local lsv {
			capture: desc `sv', varlist
			if _rc == 111 {
				di as error "RCS.prepare: ensure that at least 1 variable `sv' exists."
				error _rc
			}
			
			local lv = r(varlist)
			foreach v of local lv {
				capture: assert !missing(`v')
				if _rc == 9 {
					di as error "RCS.prepare: ensure that variable `v' has no missing values."
					error _rc
				}
			}
		}
		*make hhid sequential
		sort hhid
		egen hhidx = seq()
		drop hhid
		ren hhidx hhid
		order hhid, first
		if !`train' expand 2, gen(train)
		save "`.lc_sdTemp'/HHData-traintest.dta", replace
		drop if train
		drop train
		save "`.lc_sdTemp'/HHData.dta", replace
		use "`.lc_sdTemp'/HHData-traintest.dta", clear
		*create food and non-food files
		keep hhid hhsize weight xfood* train
		*get labels
		capture: label drop lfood
		foreach v of varlist xfood* {
			local xxx = "`v'"
			label define lfood `: subinstr local xxx "xfood" ""' "`: var label `v''", add
		}
		*reshape
		reshape long xfood, i(hhid hhsize weight train) j(foodid)
		*add labels and save
		label values foodid lfood
		save "`.lc_sdTemp'/HH-Food_traintest.dta", replace
		drop if train
		drop train
		save "`.lc_sdTemp'/HH-Food.dta", replace
		use "`.lc_sdTemp'/HHData-traintest.dta", clear
		keep hhid hhsize weight xnonfood* train
		*get labels
		capture: label drop lnonfood
		foreach v of varlist xnonfood* {
			local xxx = "`v'"
			label define lnonfood `: subinstr local xxx "xnonfood" ""' "`: var label `v''", add
		}
		*reshape
		reshape long xnonfood, i(hhid hhsize weight train) j(nonfoodid)
		*add labels and save
		label values nonfoodid lnonfood
		save "`.lc_sdTemp'/HH-NonFood_traintest.dta", replace
		drop if train
		drop train
		save "`.lc_sdTemp'/HH-NonFood.dta", replace
	}
		
	*CREATE PARTITIONS for each simulation (because of potential random)
	quiet: forvalues isim = 1 / `.nsim' {
		*check if we need to call
		capture confirm file "`.lc_sdTemp'/tstats`isim'.dta"
		if ((_rc>0) | ("`force'"!="")) {
			*food partition
			use "`.lc_sdTemp'/HH-Food_traintest.dta", clear
			.partition xfood, hhid("hhid") itemid("foodid") fweight("weight") hhsize("hhsize") nmodules(`.nmodules') ncore(`ncoref') shares(`shares')
			gen itemcode = foodid
			order itemcode, before(foodid)
			export excel using "`.lc_sdOut'/FoodConsumption.xls", sheetreplace first(var) sheet("Items (sim=`isim')")
			keep foodid itemmod itemred pcons*
			save "`.lc_sdTemp'/fsim_fpartition`isim'.dta", replace
			*non-food partition
			use "`.lc_sdTemp'/HH-NonFood_traintest.dta", clear
			.partition xnonfood, hhid("hhid") itemid("nonfoodid") fweight("weight") hhsize("hhsize") nmodules(`.nmodules') ncore(`ncorenf') shares(`shares')
			gen itemcode = nonfoodid
			order itemcode, before(nonfoodid)
			*save assignment
			export excel using "`.lc_sdOut'/NonFoodConsumption.xls", sheetreplace first(var) sheet("Items (sim=`isim')")
			keep nonfoodid itemmod itemred pcons*
			save "`.lc_sdTemp'/fsim_nfpartition`isim'.dta", replace
			
			*CALCULATE NUMBER OF QUESTIONS AND TIME NEEDED
			*merge food and non-food
			use "`.lc_sdTemp'/fsim_fpartition`isim'.dta", clear
			ren foodid nonfoodid
			append using "`.lc_sdTemp'/fsim_nfpartition`isim'.dta"
			ren nonfoodid itemid
			*calculate counts and number of yes-answers
			egen pred = total(pcons) if itemred
			egen pred_train = total(pcons_train) if itemred
			egen nred = count(pcons) if itemred
			egen nmod = max(itemmod)
			collapse (sum) pcons pcons_train (firstnm) pred pred_train nred nmod (count) ncons=itemid, by(itemmod)
			replace pred = pred[1] if missing(pred)
			replace pred_train = pred_train[1] if missing(pred_train)
			replace nred = nred[1] if missing(nred)
			ren pcons_train* pcont*
			reshape wide pcons pcont ncons, i(pred pred_train nred) j(itemmod)
			egen pq_ful = rowtotal(pcons*)
			egen pqt_ful = rowtotal(pcont*)
			egen nq_ful = rowtotal(ncons*)
			gen pq_cor = 0
			gen nq_cor = 0
			gen pqt_cor = 0
			gen nqt_cor = 0
			capture: confirm var ncons0
			if (_rc!=111) {
				replace pqt_cor = pcont0
				replace pq_cor = pcons0
				replace nq_cor = ncons0
				drop pcont0 pcons0 ncons0
			}
			egen pq_opt = rowmean(pcons*)
			egen pqt_opt = rowmean(pcont*)
			egen nq_opt = rowmean(ncons*)
			gen pq_rcs = pq_cor + pq_opt
			gen pqt_rcs = pqt_cor + pqt_opt
			gen nq_rcs = nq_cor + nq_opt
			ren (pred pred_train nred) (pq_red pqt_red nq_red)
			keep pq_* pqt_* nq_* nmod
			*get ratios for n and p
			foreach x in n p {
				if "`x'"=="n" local lx = ""
				else local lx = " asked" 
				foreach y in ful red rcs {
					gen r`x'q_`y' = `x'q_`y' / `x'q_ful
					label var r`x'q_`y' "Ratio of questions`lx' for `y'"
					label var `x'q_`y' "Number of questions`lx' for `y'"
					if ("`x'"=="p") {
						gen r`x'qt_`y' = `x'qt_`y' / `x'qt_ful
						label var r`x'qt_`y' "Ratio of training questions`lx' for `y'"
						label var `x'qt_`y' "Number of training questions`lx' for `y'"
					}
				}
				label var `x'q_cor "Number of questions`lx' for core module"
				label var `x'q_opt "Number of questions`lx' for optional module"
			}
			label var pqt_cor "Number of training questions`lx' for core module"
			label var pqt_opt "Number of training questions`lx' for optional module"
			*prepare final dataset
			order nq_* rnq_* pqt_* rpqt_* pq_* rpq_*
			order nmod *_ful *_red *_rcs *_cor *_opt
			label var nmod "Number of modules"
		}
		save "`.lc_sdTemp'/tstats`isim'.dta", replace
	}
	quiet {
		*average tstats over all module constructions
		clear
		forvalues isim=1/`.nsim' {
			append using "`.lc_sdTemp'/tstats`isim'.dta"
		}
		foreach v of var * {
			local l`v' : variable label `v'
			if "`l`v''" == "" local l`v' "`v'"
		}
		collapse (mean) nq_ful rnq_ful pqt_ful rpqt_ful pq_ful rpq_ful nq_red rnq_red pqt_red rpqt_red pq_red rpq_red nq_rcs rnq_rcs pqt_rcs rpqt_rcs pq_rcs rpq_rcs nq_cor pqt_cor pq_cor nq_opt pqt_opt pq_opt, by(nmod)
		foreach v of var * {
			label var `v' "`l`v''"
		}
		save "`.lc_sdTemp'/tstats.dta", replace
	}
	.status = 1
end
*RCS_partition xvalue, hhid("hhid") itemid("foodid") fweight("weight") hhsize("hhsize") nmodules(4) ncore(33)
*use "`lc_sdTemp'/HH-Food.dta", clear
*local xvalue = "xfood"
*local hhid = "hhid"
*local itemid = "foodid"
*local fweight= "weight"
*local hhsize = "hhsize"
*local ncore = `ncoref'
*local train = 0
program define .partition
	syntax varname, hhid(varname) itemid(varname) fweight(varname) hhsize(varname) nmodules(integer) ncore(integer) [shares(string)]
	*prepare macros
	local xvalue = "`varlist'"
	local M = `nmodules'
	quiet {
		*preserve dataset
		preserve
		keep if train
		*obtain share of household consumption (either democratic or plutocratic)
		gen wx = `xvalue' * `fweight'
		if (inlist("`shares'","","demo","democratic")) {
			bysort `hhid': egen shhx = total(`xvalue')
			replace shhx = `xvalue' / shhx * `fweight'
			bysort `itemid': egen sx = total(shhx)
			bysort `itemid': egen cx = total(`fweight')
			replace sx = sx / cx
			drop cx shhx
		}
		else if (inlist("`shares'","pluto","plutocratic")) {
			bysort `itemid': egen sx = total(wx)
			bysort `itemid': egen sweight = total(`fweight')
			replace sx = sx / sweight
			drop sweight
		}
		else if (inlist("`shares'","rnd","rand","random")) {
			gen ssx = runiform()
			bysort `itemid': egen sx = total(ssx)
			bysort `itemid': egen sweight = total(sx)
			replace sx = sx / sweight
			drop sweight ssx
		}
		else {
			dis in error "Parameter 'shares' should either be democratic, plutocratic or random."
			error 1
		}
		label var sx "Weighted average household consumption share of item"
		drop wx
		*rank share
		gsort -sx `itemid' `hhid'
		egen r = group(sx `itemid')
		quiet: summ r
		local rmax = r(max)
		local rcore = r(max) - `ncore'
		*get reduced items (core + one optional)
		local rreduced = floor((r(max) - `ncore') * (1-1/`nmodules'))
		*select core items
		gen c_x = `xvalue' if r>`rcore'
		replace `xvalue' = . if r>`rcore'
		*get next highest rank
		quiet: summ r if r<=`rcore'
		local r = r(max)
		*get food item ids in local macros
		levelsof `itemid', local(nlevels)
		levelsof `itemid' if r<=`rcore', local(nc_nlevels)
		levelsof `itemid' if r>`rcore', local(c_nlevels)
		levelsof `itemid' if r>=`rreduced', local(r_nlevels)

		*create assignment
		restore
		*aggregate
		bysort train `hhid': egen hhtot = sum(`xvalue')
		gen hhshare = `xvalue' / hhtot
		gen bcons = `xvalue'>0 & ~missing(`xvalue')
		collapse (mean) hhshare (sum) `xvalue' pcons=bcons (count) n=bcons [pweight=`fweight'], by(train `itemid')
		replace pcons = pcons / n
		bysort train: egen xtot = sum(`xvalue')
		gen totshare = `xvalue'/xtot
		drop xtot n `xvalue'
		reshape wide hhshare pcons totshare, i(`itemid') j(train)
		ren (*0 *1) (* *_train)
		label var pcons "Share of households consuming item"
		label var hhshare "Average Household Consumption Share"
		label var totshare "Consumption Share of Total Consumption"
		label var pcons_train "Share of households consuming item in training set"
		label var hhshare_train "Average Household Consumption Share in training set"
		label var totshare_train "Consumption Share of Total Consumption in training set"
		if (inlist("`shares'","","demo","democratic")) {
			gsort -hhshare_train
		}
		else if (inlist("`shares'","pluto","plutocratic")) {
			gsort -totshare_train
		}
		else if (inlist("`shares'","rnd","rand","random")) {
			gen xxr = runiform()
			sort xxr
			drop xxr
		}
		else {
			dis in error "Parameter 'shares' should either be democratic, plutocratic or random."
			error 1
		}
		*make assignment
		gen itemmod = .
		*reduced (randomization by random shares)
		gen itemred = 0
		foreach id of local r_nlevels {
			quiet: replace itemred = 1 if `itemid' == `id'
		}
		*core (randomization by random shares)
		foreach id of local c_nlevels {
			quiet: replace itemmod = 0 if `itemid' == `id'
		}
		*non-core - always random
		egen xitemmod = seq() if missing(itemmod), from(1) to(`M')
		replace itemmod = xitemmod if missing(itemmod)
		drop xitemmod
		label var itemmod "Module number for item"
		label var itemred "In reduced item set"
	}
end
*RCS_describe prepares some stats from the initial dataset
* parameter:
*   using: input file for RCS
*   dirbase: directory for output
program define .describe
	*check preparations
	if .status == 0 {
		di as error "RCS.describe: please first run RCS.prepare."
		error 1
	}
	use "`.lc_sdTemp'/HHData.dta", clear
	*histogram for administered items
	egen xc = anycount(xfood*), values(0)
	egen n_food = rownonmiss(xfood*)
	gen x_food = n_food - xc
	label var n_food "Number of food items"
	label var x_food "Consumed food items"
	hist x_food, freq ylabel(,angle(0)) graphregion(color(white)) bgcolor(white) bcolor(eltblue) name(gRCS_xfood, replace)
	egen t_food = rowtotal(xfood*)
	label var t_food "Food consumption"
	quiet: summ t_food, d
	scatter t_food x_food if t_food<`r(p95)' || lfit t_food x_food if t_food<`r(p95)', ylabel(,angle(0)) legend(size(small)) graphregion(color(white)) bgcolor(white) bcolor(eltblue) name(gRCS_tfood, replace)
	drop xc t_food
	*non food
	egen xc = anycount(xnonfood*), values(0)
	egen n_nonfood = rownonmiss(xnonfood*)
	gen x_nonfood = n_nonfood - xc
	label var n_nonfood "Number of non-food items"
	label var x_nonfood "Consumed non-food items"
	hist x_nonfood, freq ylabel(,angle(0)) graphregion(color(white)) bgcolor(white) bcolor(eltblue) name(gRCS_xnonfood, replace)
	egen t_nonfood = rowtotal(xnonfood*)
	label var t_nonfood "Non-food consumption"
	quiet: summ t_nonfood, d
	scatter t_nonfood x_nonfood if t_nonfood<`r(p95)' || lfit t_nonfood x_nonfood if t_nonfood<`r(p95)', ylabel(,angle(0)) legend(size(small)) graphregion(color(white)) bgcolor(white) bcolor(eltblue) name(gRCS_tnonfood, replace)
	summ x_food n_food x_nonfood n_nonfood
	drop xc n_food n_nonfood x_food x_nonfood t_nonfood
	*produce combined graph
	graph combine gRCS_xfood gRCS_xnonfood gRCS_tfood gRCS_tnonfood, graphregion(color(white)) name(gRCS_xcmb, replace)
	graph export "`.lc_sdOut'/descr_nitems.png", replace
	graph drop gRCS_xfood gRCS_tfood gRCS_xnonfood gRCS_tnonfood gRCS_xcmb
end

* RCS_mask: creates one output file per simulation with masked consumption
* parameters:
*   using: prepared dataset for analysis
*   dirbase: folder root to save files in Temp and Out folders
*   nmodules: number of modules to split items into
*   rseed: random seed for reproducibility
*   Prob: 0-1: probability for an item to be administered in detail (instead of just y/n)
*         >1: maximum number of items to be administered in detail (instead of just y/n)
program define .mask
	syntax , [force Prob(real 1.0)]
	*check preparations
	if `.status' < 1 {
		di as error "RCS.mask: please first run RCS.prepare."
		error 1
	}
	set seed `.rseed'
	.prob = `prob'
	*start iteration over simulations
	quiet: forvalues isim = 1 / `.nsim' {
		capture: confirm file "`.lc_sdTemp'/mi_`isim'.dta"
		if ((_rc>0) | ("`force'"!="")) {
			*get reduced aggregate from training set, to calculate poverty line for LLO
			*reduced consumption for food
			use "`.lc_sdTemp'/HH-Food_traintest.dta", clear
			keep if train
			merge m:1 foodid using "`.lc_sdTemp'/fsim_fpartition`isim'.dta", nogen assert(match) keepusing(itemred)
			gen xfcons_r = xfood if itemred
			collapse (sum) xfcons_r, by(hhid)
			tempfile tfood
			save "`tfood'", replace
			*reduced consumption for non food
			use "`.lc_sdTemp'/HH-NonFood_traintest.dta", clear
			keep if train
			*get reduced food consumption
			merge m:1 nonfoodid using "`.lc_sdTemp'/fsim_nfpartition`isim'.dta", nogen assert(match) keepusing(itemred)
			gen xnfcons_r = xnonfood if itemred
			collapse (sum) xnfcons_r, by(hhid train)
			merge 1:1 hhid using "`tfood'", nogen assert(match)
			gen red = xfcons_r + xnfcons_r
			merge 1:1 hhid train using "`.lc_sdTemp'/HHData-traintest.dta", nogen keep(match) keepusing(weight hhsize)
			*obtain poverty lines for LLO 2011
			_pctile red [pweight=weight*hhsize], nq(100)
			clear
			set obs 1
			gen simulation = `isim'
			forvalues i = 1/100 {
				gen pline_llo`i' = r(r`i')
			}
			if (`isim'>1) append using "`.lc_sdTemp'/pline_llo.dta"
			save "`.lc_sdTemp'/pline_llo.dta", replace

			*START with the real dataset
			*get household assignment to modules
			use "`.lc_sdTemp'/HHData.dta", clear
			keep hhid cluster weight
			*start module assignment randomly per cluster to make sure they are uniformly across clusters
			gen r = runiform()
			sort cluster r
			*get random start value for sequence for each cluster
			by cluster: egen i = seq()
			gen module = 1+int((`.nmodules')*runiform()) if i==1
			bysort cluster: replace module = mod(module[_n-1],`.nmodules')+1 if i>1
			label var module "Optional food module assigned to household"
			*get non-food module (same as food module by definition)
			gen module_nf = module
			keep hhid module module_nf
			ren module hhmod_f 
			ren module_nf hhmod_nf
			label var hhmod_nf "Optional non-food module assigned to household"
			save "`.lc_sdTemp'/HH-ModuleAssignment.dta", replace

			*prepare dataset for MI 
			*FOOD CONSUMPTION
			use "`.lc_sdTemp'/HH-Food.dta", clear
			*get household assigned module
			merge m:1 hhid using "`.lc_sdTemp'/HH-ModuleAssignment.dta", nogen assert(match) keepusing(hhmod_f)
			ren hhmod_f hhmod
			*add food assigned  module
			merge m:1 foodid using "`.lc_sdTemp'/fsim_fpartition`isim'.dta", nogen assert(match) keepusing(itemmod itemred)
			*get reduced food consumption
			gen xfred = xfood if itemred
			bysort hhid: egen rfcons = sum(xfred)
			drop xfred itemred
			*get total food consumption
			bysort hhid: egen cfcons = sum(xfood)
			*remove consumption that is not assigned
			replace xfood = .z if (itemmod>0) & (itemmod!=hhmod)
			*add binary yes/no indicator whether food is consumed
			gen bfitem = xfood>0 if !missing(xfood)
			replace bfitem = .z if xfood==.z
			*mask consumption items with defined probability or maximum number (if not administered)
			gen r = runiform() if ~missing(bfitem) & (bfitem==1)
			if (`.prob'<=1) {
				replace xfood = .y if ~missing(r) & (r>`.prob')
			}
			else {
				bysort hhid: egen rk = rank(r) if ~missing(r), unique
				replace xfood = .y if (rk>`.prob') & ~missing(r)
				drop rk
			}
			drop r
			*create module consumption
			forvalues kmod = 0/`.nmodules' {
				capture: bysort hhid itemmod: egen cxfood`kmod' = total(xfood) if (itemmod==`kmod') & ((`kmod'==0) | (hhmod==`kmod'))
				quiet: bysort hhid: egen xfcons`kmod' = max(cxfood`kmod')
				drop cxfood`kmod'
			}
			replace xfcons0 = 0 if missing(xfcons0)
			*make items columns and one record per hh
			ren xfood xfitem
			drop itemmod
			reshape wide xfitem bfitem, i(hhid hhmod weight) j(foodid)
			keep hhid hhmod weight cfcons rfcons xfcons* xfitem* bfitem* 
			order hhid hhmod weight cfcons rfcons xfcons* xfitem* bfitem*
			*ensure assigned modules are not missing and non-assigned are missing
			forvalues jmod = 1/`.nmodules' {
				assert !missing(xfcons`jmod') if (hhmod==`jmod')
				assert missing(xfcons`jmod') if (hhmod!=`jmod')
			}
			*check whether administered consumption is equal to module consumption
			egen xt_items = rowtotal(xfitem*)
			egen xt_mods = rowtotal(xfcons*)
			assert round(xt_items-xt_mods,.1)==0
			drop xt_*
			save "`.lc_sdTemp'/hh-food-consumption.dta", replace
			
			*NON-FOOD CONSUMPTION
			use "`.lc_sdTemp'/HH-NonFood.dta", clear
			*get household assigned module
			merge m:1 hhid using "`.lc_sdTemp'/HH-ModuleAssignment.dta", nogen assert(match) keepusing(hhmod_f)
			ren hhmod_f hhmod
			*add food assigned  module
			merge m:1 nonfoodid using "`.lc_sdTemp'/fsim_nfpartition`isim'.dta", nogen assert(match) keepusing(itemmod itemred)
			*get reduced food consumption
			gen xnfred = xnonfood if itemred
			bysort hhid: egen rnfcons = sum(xnfred)
			drop xnfred itemred
			*get total consumption
			bysort hhid: egen cnfcons = sum(xnonfood)
			*remove consumption that is not assigned
			replace xnonfood = .z if (itemmod>0) & (itemmod!=hhmod)
			*add binary yes/no indicator whether food is consumed (for assigned modules)
			gen bnfitem = xnonfood>0 if !missing(xnonfood)
			replace bnfitem = .z if xnonfood==.z
			*mask consumption items with defined probability or maximum number (if not administered)
			gen r = runiform() if ~missing(bnfitem) & (bnfitem==1)
			if (`.prob'<=1) {
				replace xnonfood = .y if ~missing(r) & (r>`.prob')
			}
			else {
				bysort hhid: egen rk = rank(r) if ~missing(r), unique
				replace xnonfood = .y if (rk>`.prob') & ~missing(r)
				drop rk
			}
			drop r
			*create module consumption
			forvalues kmod = 0/`.nmodules' {
				bysort hhid itemmod: egen cxnfood`kmod' = total(xnonfood) if (itemmod==`kmod') & ((`kmod'==0) | (hhmod==`kmod'))
				bysort hhid: egen xnfcons`kmod' = max(cxnfood`kmod')
				drop cxnfood`kmod'
			}
			replace xnfcons0 = 0 if missing(xnfcons0)
			*make items columns and one record per hh
			ren xnonfood xnfitem
			drop itemmod
			reshape wide xnfitem bnfitem, i(hhid hhmod weight) j(nonfoodid)
			keep hhid hhmod weight cnfcons rnfcons xnfcons* xnfitem* bnfitem* 
			order hhid hhmod weight cnfcons rnfcons xnfcons* xnfitem* bnfitem*
			*ensure assigned modules are not missing and non-assigned are missing
			forvalues jmod = 1/`.nmodules' {
				assert !missing(xnfcons`jmod') if (hhmod==`jmod')
				assert missing(xnfcons`jmod') if (hhmod!=`jmod')
			}
			*check whether administered consumption is equal to module consumption
			egen xt_items = rowtotal(xnfitem*)
			egen xt_mods = rowtotal(xnfcons*)
			if (`.prob'==1) assert round(xt_items-xt_mods,.1)==0
			drop xt_*
			compress
			save "`.lc_sdTemp'/hh-nonfood-consumption.dta", replace

			*merge food and non-food
			use "`.lc_sdTemp'/HHData.dta", clear
			drop xfood* xnonfood*
			merge 1:1 hhid using "`.lc_sdTemp'/hh-food-consumption.dta", nogen assert(master match)
			merge 1:1 hhid using "`.lc_sdTemp'/hh-nonfood-consumption.dta", nogen assert(master match)
			order cfcons rfcons xfcons* cnfcons rnfcons xnfcons* xf* bf* xnf* bnf*, last
			*create percentiles
			foreach v of varlist xfcons0 xnfcons0 xdurables {
				xtile p`v' = `v' [pweight=weight], nquantiles(4)
			}
			*prepare check variables
			gen ccons = cfcons + cnfcons + xdurables
			gen rcons = rfcons + rnfcons + xdurables
			compress
			save "`.lc_sdTemp'/mi_`isim'.dta", replace
		}
	}
	.status = 2
end

*will call RCS_estimate_`smethod' defined in fRCS_estimate_.do
program define .estimate
	syntax , lmethod(namelist) [force nmi(integer 1) method(namelist min=1 max=2)]
	*check preparations
	if `.status' < 2 {
		di as error "RCS.estimate: please first run RCS.prepare followed by RCS.mask."
		error 1
	}
	set seed `.rseed'
	*make sure number of imputations remain constant across calls of function
	if missing(`.nmi') {
		.nmi = `nmi'
	} 
	else if (`.nmi'!=`nmi'){
		di as error "RCS.estimate has been called more than once but with different number of imputations. Must remain constant. Reverting to `.nmi' imputations."
	}
	if ("`lmethod'"=="") {
		.lmethod = "`lmethod'"
	}
	else {
		foreach v of local lmethod {
			if !strpos("`.lmethod'","`v'") .lmethod = "`.lmethod' `v'"
		}
	}
	quiet {
		*setup estimator
		use "`.lc_sdTemp'/mi_1.dta", clear
		*prepare dataset for estimation
		unab mcon : mcon_*
		fvunab mcat : i.mcat_*
		capture confirm file "`.lc_sdTemp'/model.txt"
		local model = ""
		local logmodel = ""
		if ((_rc==0) & ("`force'"=="")) {
			*load saved models
			capture file close fhm
			file open fhm using "`.lc_sdTemp'/model.txt", read
			file read fhm model 
			file read fhm logmodel
			file close fhm
			quiet: xi i.strata i.pxdurables `mcat'
		}
		.estimator.prepare , hhid("hhid") weight("weight") hhmod("hhmod") cluster("cluster") xfcons("xfcons") xnfcons("xnfcons") nmi(`.nmi')
		.estimator.select_model hhsize urban i.pxdurables `mcon' `mcat', fix("i.strata") model("`model'") logmodel("`logmodel'") method("`method'")
		esttab using "`.lc_sdOut'/Model.csv", r2 ar2 aic replace
		eststo clear
		*save models
		capture file close fhm
		file open fhm using "`.lc_sdTemp'/model.txt", replace write
		file write fhm "`.estimator.model'" _n "`.estimator.logmodel'"
		file close fhm
		*change to temp directory for mi commands
		cd "`.lc_sdTemp'"
	}
	*start iteration over simulations
	forvalues isim = 1 / `.nsim' {
		di "Entering simulation `isim' ($S_DATE $S_TIME):"
		*ESTIMATE BASED ON DIFFERENT METHODS
		foreach smethod of local lmethod {
			di " ... running for `smethod' ..."
			capture: confirm file "`.lc_sdTemp'/sim_`smethod'_`isim'.dta"
			if ((_rc>0) | ("`force'"~="")) {
				*load ratio of questions for swift2 comparison
				use "`.lc_sdTemp'/tstats`isim'.dta", clear
				local pq = rpq_rcs[1]
				*load prepared dataset for mi
				use "`.lc_sdTemp'/mi_`isim'.dta", clear				
				quiet: xi i.strata i.pxdurables `mcat'
				*prepare variables
				foreach v of varlist xfcons? xnfcons? xdurables {
					*save original
					quiet: gen o`v' = `v'
				}
				*method selection
				local mipre = ""
				quiet: .estimator.estimate , method("`smethod'") pq(`pq')
				*flag for mi dataset
				quiet: mi query
				if "`r(style)'"!="" local mipre = "mi passive:"
				else local mipre = ""
				*create consumption aggregate if not done in .estimate
				capture: confirm variable xcons
				if _rc>0 {
					quiet: gen xcons = .
					if ("`mipre'"!="") quiet: mi register passive xcons
					*build aggregates; but replace with originals if available
					quiet: `mipre' replace xcons = xdurables
					foreach v of varlist xfcons? xnfcons? {
						quiet: `mipre' replace xcons = xcons + o`v' if ~missing(o`v')
						quiet: `mipre' replace xcons = xcons + `v' if missing(o`v')
					}
				}
				*cleaning
				if ("`mipre'"!="") {
					quiet: keep hhid xcons ccons rcons _*xcons _mi*
					quiet: mi register imputed xcons
					quiet: mi update
				}
				else {
					keep hhid xcons ccons rcons
				}
				quiet: compress
				quiet: save "`.lc_sdTemp'/sim_`smethod'_`isim'.dta", replace
				*ensure .collate is re-run afterwards
				capture: erase "`.lc_sdTemp'/simd_`smethod'.dta", replace
			}
			*add to lmethod
			if !strpos("`.lmethod'","`smethod'") .lmethod = "`.lmethod' `smethod'"
		}
	}
	.status = 3
end

program define .collate
	syntax , [force]
	*check preparations
	if `.status' < 3 {
		di as error "RCS.collate: please first run RCS.prepare followed by RCS.mask and RCS.estimate."
		error 1
	}

	*change to temp directory for mi commands
	quiet: cd "`.lc_sdTemp'"
	*extract detailed results from estimation
	foreach smethod in `.lmethod' {
		di "Extracting for `smethod':"
		capture: confirm file "`.lc_sdTemp'/simd_`smethod'.dta"
		if ((_rc>0) | ("`force'"!="")) {
			quiet: forvalues isim = 1/`.nsim' {
				use "`.lc_sdTemp'/sim_`smethod'_`isim'.dta", clear
				gen simulation = `isim'
				mi query
				if ("`r(style)'"=="") {
					if (`isim'==1) {
						*extract reference and reduced
						ren (xcons ccons rcons) (est1 est0 est99)
						reshape long est, i(hhid) j(x)
						recode x (99=-1)
						replace simulation = x
						drop x
					}
					else {
						ren xcons est
						drop ccons rcons
					}
					gen imputation = (simulation>0)
				}
				else {
					*convert to long format and get observation for reference and reduced
					mi convert flong, clear
					mi unset
					ren (mi_m xcons) (imputation est)
					if (`isim'==1) {
						expand 2 if imputation==0, gen(x)
						replace imputation = -1 if x==1
						drop x
						*move ref/red indicator from Imputation to Simulation level
						replace est = ccons if imputation==0
						replace est = rcons if imputation==-1
						replace simulation = imputation if imputation <1
						replace imputation = 0 if imputation < 1
					}
					else {
						drop if imputation<1
					}
				}
				keep simulation imputation hhid est
				order simulation imputation hhid est
				*append simulations
				if (`isim'>1) {
					append using "`.lc_sdTemp'/simd_`smethod'.dta"
				}
				save "`.lc_sdTemp'/simd_`smethod'.dta", replace
			}
			quiet {
				*prepare analysis file
				merge m:1 hhid using "`.lc_sdTemp'/HHData.dta", nogen keep(match) keepusing(weight cluster urban)
				*get reference
				gen x = est if simulation==0
				bysort hhid: egen ref = max(x)
				drop x
				drop if simulation==0
				order ref, after(est)
				*get reduced aggregate
				gen x = est if simulation==-1
				bysort hhid: egen red = max(x)
				drop x
				drop if simulation==-1
				order red, after(ref)
				*save for analysis
				save "`.lc_sdTemp'/simd_`smethod'_imp.dta", replace
				*collapse imputations
				bysort simulation hhid: egen x = mean(est)
				replace est = x
				drop x
				drop if imputation>1
				drop imputation
				save "`.lc_sdTemp'/simd_`smethod'.dta", replace
				capture: erase "`.lc_sdTemp'/simd_`smethod'_stats.dta", replace
			}
		}
	}
	.status = 4
end

*analyzes dataset for all poverty lines	(and programmed more efficiently than the pl version)
*   urban: -1: no restriction, 0: rural only, 1: urban only
program define .analyze
	syntax , [force Urban(integer -1)]
	*check preparations
	if `.status' < 4 {
		di as error "RCS.analyze: please first run RCS.prepare followed by RCS.mask, RCS.estimate and RCS.collate."
		error 1
	}
	
	*configure urban/rural filter
	local sfsuff = ""
	local sdrop = " if urban==1-`urban'" 
	if (`urban'==0) {
		local sfsuff = "-rural"
	}
	else if (`urban'==1) {
		local sfsuff = "-urban"
	}	
	*prepare datasets also for ref and red
	quiet {
		use "`.lc_sdTemp'/simd_`: word 1 of `.lmethod''_imp.dta", clear
		keep if imputation==1
		drop est
		ren ref est
		save "`.lc_sdTemp'/simd_ref_imp.dta", replace
		ren est ref
		ren red est
		save "`.lc_sdTemp'/simd_red_imp.dta", replace
		*save dataset for evaluating LLO method - though it's the same as reduced
		save "`.lc_sdTemp'/simd_llo_imp.dta", replace
		ren est red
		drop `sdrop'
		merge m:1 hhid using "`.lc_sdTemp'/HHData.dta", assert(using match) keep(match) keepusing(hhsize) nogen
		compress
	}
	local lredmeth = "red llo `.lmethod'"
	local lrefredmeth = "ref `lredmeth'"
	*analyze FGTs performance with range of poverty lines
	di "Analyze FGT0 bias for each percentile..."
	*obtain poverty lines
	_pctile ref if simulation==1 & imputation==1 [pweight=weight*hhsize], nq(100)
	quiet forvalues i = 1/100 {
		*use local macro for reference pline
		local pline`i' = r(r`i')
		*use merged variable for LLO poverty lines (variable across simulations if random core)
		local pline_llo`i' = "pline_llo`i'"
	}
	*calculate FGTs and gini for list of poverty lines
	di "  Calculating FGT and Gini: " _newline "    " _continue
	foreach v of local lrefredmeth {
		di "`v' " _continue
		capture: confirm file "`.lc_sdTemp'/simd_`v'_stats.dta"
		if ((_rc>0) | ("`force'"!="")) {
			quiet {
				*for memory reasons, it is better to run by simulation
				use "`.lc_sdTemp'/simd_`v'_imp.dta", clear
				levelsof simulation, local(nsim)
				foreach isim of local nsim {
					*prepare dataset
					use "`.lc_sdTemp'/simd_`v'_imp.dta", clear
					keep if simulation==`isim'
					drop `sdrop'
					merge m:1 hhid using "`.lc_sdTemp'/HHData.dta", assert(using match) keep(match) keepusing(hhsize) nogen
					summ imputation
					local b = 10^ceil(log10(r(max)))
					replace hhid = hhid * `b' + imputation
					drop imputation
					*allow different poverty lines
					local pline = "pline"
					if "`v'"=="llo" {
						local pline = "pline_llo"
						merge m:1 simulation using "`.lc_sdTemp'/`pline'.dta", nogen assert(match using) keep(match) keepusing("`pline'*")
					}
					*calculate FGT
					sort simulation est
					forvalues i = 1/100 {
						gen x_fgt0_i`i' = est < ``pline'`i''  if ~missing(est)
						gen x_fgt1_i`i' = max(``pline'`i'' - est,0) / ``pline'`i'' if ~missing(est)
						gen x_fgt2_i`i' = x_fgt1_i`i'^2 if ~missing(est)
					}
					*calculate gini (note that this always needs to be done by simulation)
					quiet: fastgini est [pweight=weight*hhsize]
					gen x_gini = r(gini)
					*summarize
					collapse (mean) x_* [pweight=weight*hhsize], by(simulation)
					if `isim'==1 save "`.lc_sdTemp'/simd_`v'_stats.dta", replace
					else {
						append using "`.lc_sdTemp'/simd_`v'_stats.dta"
						save "`.lc_sdTemp'/simd_`v'_stats.dta", replace
					}
				}
				capture: erase "`.lc_sdTemp'/simd_`v'_pstats.dta"
			}
		}
	}
	*get performance statistics
	di _n "  Calculating performance indicators..."
	quiet foreach sm of local lredmeth {
		capture: confirm file "`.lc_sdTemp'/simd_`sm'_pstats.dta"
		if ((_rc>0) | ("`force'"!="")) {
			use "`.lc_sdTemp'/simd_ref_stats.dta", clear
			ren x_* r_*
			merge 1:1 simulation using "`.lc_sdTemp'/simd_`sm'_stats.dta", assert(match) keep(match) nogen		
			fse r_gini x_gini
			gen p_bias_gini = r(bias)
			gen p_se_gini = r(se)
			gen p_rbias_gini = r(rbias)
			gen p_rse_gini = r(rse)
			gen p_rmse_gini = r(rmse)
			gen p_cv_gini = r(cv)
			local stubs = ""
			foreach ind in fgt0 fgt1 fgt2 {
				local stubs = "`stubs' x_`ind'_i r_`ind'_i"
				forvalues i = 1/100 {
					fse r_`ind'_i`i' x_`ind'_i`i'
					gen p_bias_`ind'_i`i' = r(bias)
					gen p_se_`ind'_i`i' = r(se)
					gen p_rbias_`ind'_i`i' = r(rbias)
					gen p_rse_`ind'_i`i' = r(rse)
					gen p_rmse_`ind'_i`i' = r(rmse)
					gen p_cv_`ind'_i`i' = r(cv)
				}
				local stubs = "`stubs' p_bias_`ind'_i p_se_`ind'_i p_rbias_`ind'_i p_rse_`ind'_i p_rmse_`ind'_i p_cv_`ind'_i"
			}
			*reorganize
			reshape long `stubs', i(simulation) j(i)
			ren *_i *
			reshape long r_ x_ p_bias_ p_se_ p_rbias_ p_rse_ p_rmse_ p_cv_, i(simulation i) j(indicator) string
			ren *_ *
			gen method = "`sm'"
			label var i "poverty line percentile"
			label var r "reference value"
			label var x "estimated value"
			order method, after(i)
			save "`.lc_sdTemp'/simd_`sm'_pstats.dta", replace
		}
	}
	*assemble
	use "`.lc_sdTemp'/simd_red_pstats.dta", clear
	append using "`.lc_sdTemp'/simd_llo_pstats.dta"
	local lmethod = "`.lmethod'"
	quiet foreach sm of local lmethod {
		append using "`.lc_sdTemp'/simd_`sm'_pstats.dta"
	}
	save "`.lc_sdTemp'/simd_pstats.dta", replace
	*output table for differences with reference
	quiet {
		gen d = x - r
		gen dabs = abs(d)
		collapse (mean) d dabs p_*, by(method indicator i)
		*produce graph
		encode method, gen(imethod)
		encode indicator, gen(iindicator)
		gen int id = imethod * 1000 + iindicator
		levelsof id, local(lid)
		foreach id of local lid {
			local j = floor(`id'/1000)
			label define id `id' "`:label imethod `j''", modify
		}
		label values id id
		label var d "deviation"
		tsset id i
		local gcmb = ""
		local legend = ""
	}
	quiet foreach ind in fgt0 fgt1 fgt2 gini {
		xtline d if indicator=="`ind'", overlay name(g`ind') ylabel(,angle(0)) title("`ind'") `legend'
		local legend = "legend(off)"
		local gcmb = "`gcmb' g`ind'"
	}
	capture which grc1leg2
	if _rc==111 {
		graph combine `gcmb', name(gcmb)
	}
	else {
		grc1leg2 `gcmb', name(gcmb)
	}
	graph export "`.lc_sdOut'/fgt`sfsuff'.png", replace	
	graph drop `gcmb'
	capture: graph drop g_dabs
	graph bar (mean) dabs, over(method, label(angle(45))) over(indicator) title("Average Absolute Deviation") ylabel(,angle(0)) ytitle("") name(g_dabs)
	graph export "`.lc_sdOut'/fgt-avg`sfsuff'.png", replace
	export excel "`.lc_sdOut'/fgt`sfsuff'.xls", replace sheet("Percentiles") firstrow(var)
	collapse (mean) d dabs p_*, by(method indicator)
	export excel "`.lc_sdOut'/fgt`sfsuff'.xls", sheetreplace sheet("Averages") firstrow(var)
	*output average performance statistics
	use "`.lc_sdTemp'/simd_pstats.dta", clear
	drop r x
	quiet: reshape long p_, i(simulation i indicator method) j(metric) string
	ren p_ p
	collapse (mean) p, by(i method indicator metric)
	capture: graph drop g_metric
	graph bar (mean) p, over(method, label(angle(45) labsize(tiny))) over(indicator) by(metric, yrescale) ylabel(,angle(0)) name(g_metric)
	graph export "`.lc_sdOut'/metrics`sfsuff'.png", replace
	graph drop g_metric g_dabs gcmb
	table method indicator metric, c(mean p) format(%9.2f)
	save "`.lc_sdOut'/metrics`sfsuff'.dta", replace
	gen nmod = `.nmodules'
	quiet merge m:1 nmod using "`.lc_sdTemp'/tstats.dta", nogen
end

*cleans up the large temp folder
program define .cleanup
	syntax
	*delete temp files
	shell rmdir "`.lc_sdTemp'" /s /q
	*reset status
	.status = 0
end	

program define .run
	syntax using/, dirbase(string) nmodules(integer) ncoref(integer) ncorenf(integer) nsim(integer) nmi(integer) lmethod(namelist) [force erase train(integer 0) shares(string) rseed(integer 230880) Prob(real 1.0)]
	.prepare using "`using'", dirbase("`dirbase'") nsim(`nsim') nmodules(`nmodules') ncoref(`ncoref') ncorenf(`ncorenf') train(`train') shares("`shares'") rseed(`rseed') `force' `erase'
	.mask , prob(`prob') `force'
	.estimate , lmethod("`lmethod'") nmi(`nmi') `force'
	.collate , `force'
	.analyze , `force'
end
